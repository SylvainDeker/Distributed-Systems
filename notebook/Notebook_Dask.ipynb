{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dask presentation\n",
    "This notebook is a quick demonstration of the DASK library. DASK is designed for distributed computing in Python. The architecture of such a system possesses a Scheduler, several Workers and several clients (only one client is used here). The user who wants to run distributed computing connects its client to the scheduler, then the scheduler divides data into 'partitions' and assignes them to the different workers. In this notebook, Client() is configured in distributed mode but runs locally the scheduler and the workers by itself.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "import dask.bag as db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sylvain/.local/lib/python3.7/site-packages/distributed/dashboard/core.py:79: UserWarning: \n",
      "Port 8787 is already in use. \n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the diagnostics dashboard on a random port instead.\n",
      "  warnings.warn(\"\\n\" + msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:42509</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:39703/status' target='_blank'>http://127.0.0.1:39703/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>5</li>\n",
       "  <li><b>Cores: </b>5</li>\n",
       "  <li><b>Memory: </b>8.22 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:42509' processes=5 threads=5, memory=8.22 GB>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = Client(n_workers=5,threads_per_worker=1)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask provides differents user interfaces, which are:\n",
    "- Bag: A dask.bag is an unordered collection allowing repeats. \n",
    "- Array: A dask.array is an array of the same element.\n",
    "- DataFrame: A dask.dataFrame is a data structure like a dictionary that contains heterogeneous data accessible by 'labels'.\n",
    "- Delayed: A dask.delayed is a low-level way to define one or several tasks\n",
    "- Futures: A dask.future is a low-level way to execute real-time computing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask.bag\n",
    "Dask.bag allows operations usually used in functional programming like map, filter and fold. The computation is lazy until the method '.compute()' is called. Let's start with an example of list of string (here a string contains a number). The argument npartitions=5 is optionnal, it is set to 5 here for an in-depth understanding of the system behavior. Given the short lenght of the list, if this optional argument was not set explicitly, it would automaticaly be set to 1, hence without any parallelization. The method .from_sequence() loads data from the client to the scheduler so we usually set a small amount of data in the list (ex: filenames, references, indexes, etc...). The result returned is a dask.bag, an object on which it is possible to apply lazy computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = db.from_sequence(['0','1','2','3','4','5','6','7','8',\n",
    "                        '9','10','11','12'],npartitions=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The map() applies the function passed through the argument to each element. Here, our function convert each 'string' to 'int'. If we have had filenames, url, ..  , we would have load/download the content the same way. The result would be:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = rdd.map(lambda e: int(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The filter() applies a boolean function passed through the argument to each element and allows to make a selection onto the elements we want to keep. Here the function returns True if the element 'e' is even and False else. The result would be: [0, 2, 4, 6, 8, 10, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = rdd.filter(lambda e:e%2==0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fold() method is a 'Higher order function' that iterates binary operation over a list in a recursive way. The Dask's fold function parrallelizes automatically this operation. The restriction with dask.fold lies in that the binary function (in argument) must be associative in order to have a predictive result. Let's see why,\n",
    "in theory, two kinds of fold operation exist: fold left and fold right, one for each associative side. See the figure below.\n",
    "![fold_left_right](fold_left_right.png)\n",
    "In distributed/parallelized way, the process is quite different; several parts are executed alongside each other in foldleft way and the result of each partitions is then aggregated to each other. Let's see below one example of the execution tree could be:\n",
    "![fold_left_right](fold_dask.png)\n",
    "Combine function is the function that combines the results from two partitions. This function is the same as 'binop'(=f in pictures) as long as no 'combine' function is not explicitly defined. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = rdd.fold(binop=lambda acc, e: acc+e, initial=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the functions described above do not compute. They build a graph of dependances of the different steps of the calculation. The method '.compute()' is the function that triggers computation thanks to this graph. The result computed on workers is then brought back to client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another interesting method provided by DASK is '.foldby()'. The foldby has the same ability of '.fold()' but it acts over different subgroups that we define by a criteria; the 'key'. Let's have an example below:\n",
    "We have a collection built from cities and their associated zip code. We want to group cities by state departement (The first two digits of the zip code identify the state departement)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = db.from_sequence([\n",
    "('Balma',31130),\n",
    "('Blagnac',31700),\n",
    "('Ramonville-Saint-Agne',31520),\n",
    "('Vieille-Toulouse',31320),\n",
    "('L\\'Union',31240),\n",
    "('Portet-sur-Garonne',31120),\n",
    "('Tournefeuille',31170),\n",
    "('Suresnes', 92150),\n",
    "('Nanterre', 92000),\n",
    "('La Garenne-Colombes', 92250),\n",
    "('Bobigny', 93000),\n",
    "('Montreuil', 93100)],npartitions=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key function takes the first two digits of the zip code and the binop function takes the current city and add it to an accumulator 'acc[0]+b[0]'. The binop function needs to have the same data structure for each argument and for the return, hence the (acc[0]+b[0],)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(31,\n",
       "  (['Balma',\n",
       "    'Blagnac',\n",
       "    'Ramonville-Saint-Agne',\n",
       "    'Vieille-Toulouse',\n",
       "    \"L'Union\",\n",
       "    'Portet-sur-Garonne',\n",
       "    'Tournefeuille'],)),\n",
       " (92, (['Suresnes', 'Nanterre', 'La Garenne-Colombes'],)),\n",
       " (93, (['Bobigny', 'Montreuil'],))]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = rdd.foldby(key=lambda e:int(e[1]/1000),\n",
    "                binop=lambda acc,b:(acc[0]+[ b[0] ],), initial=([],),\n",
    "                combine=lambda a,b:(a[0]+b[0],))\n",
    "rdd.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Limitations\n",
    "[https://docs.dask.org/en/latest/bag.html#known-limitations](https://docs.dask.org/en/latest/bag.html#known-limitations)\n",
    "\n",
    "Bags provide very general computation (any Python function). This generality comes at cost. Bags have the following known limitations:\n",
    "\n",
    "1. By default, they rely on the multiprocessing scheduler, which has its own set of known limitations (see Shared Memory)\n",
    "2. Bags are immutable and so you can not change individual elements\n",
    "3. Bag operations tend to be slower than array/DataFrame computations in the same way that standard Python containers tend to be slower than NumPy arrays and Pandas DataFrames\n",
    "4. Bag’s groupby is slow. You should try to use Bag’s foldby if possible. Using foldby requires more thought though\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask.array\n",
    "A dask array is an array of Numpy array. The dask.array API is very, very similar to the NumPy.ndarray API, but all the methods from NumPy are not implemented in DASK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "a = da.random.random(10000, chunks=100)\n",
    "b = da.random.random(10000, chunks=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, for example, we compute the distance between two points a and b along the 10000 dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.83291741417142"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = da.linalg.norm(a-b)\n",
    "dist.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask.dataframe\n",
    "As Dask.array copies NumPy.ndarray, Dask.dataframe copies dataframe and dataSerie from Pandas. A dataFrame is a list of dataseries, a structure like a dictionary that contains heterogeneous data reachable by labels.\n",
    "In the following example, we load csv that contains information about car sales. What we decide to do is to extract a list of the 10 top car price lower than €40000. The main interest of dataseries is that they are indexed and they can be sorted. Such a process is not possible with the dask.bag and the dask.array (by default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "df = dd.read_csv('cars.csv',delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>model</th>\n",
       "      <th>year</th>\n",
       "      <th>km</th>\n",
       "      <th>power</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LEXUS</th>\n",
       "      <td>NX</td>\n",
       "      <td>NX 300h 4WD</td>\n",
       "      <td>2015</td>\n",
       "      <td>39 816</td>\n",
       "      <td>Essence / Courant Électrique</td>\n",
       "      <td>31980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RENAULT</th>\n",
       "      <td>TALISMAN</td>\n",
       "      <td>Talisman dCi 130 Energy</td>\n",
       "      <td>2015</td>\n",
       "      <td>24416</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>19490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RENAULT</th>\n",
       "      <td>ESPACE</td>\n",
       "      <td>Espace dCi 160 Energy Twin Turbo</td>\n",
       "      <td>2015</td>\n",
       "      <td>51800</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>18990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMW</th>\n",
       "      <td>SERIE 2</td>\n",
       "      <td>Active Tourer 218d 150 ch</td>\n",
       "      <td>2015</td>\n",
       "      <td>49819</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>18900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RENAULT</th>\n",
       "      <td>KOLEOS</td>\n",
       "      <td>Koleos 2.0 dCi 150</td>\n",
       "      <td>2015</td>\n",
       "      <td>62731</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>15990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RENAULT</th>\n",
       "      <td>KOLEOS</td>\n",
       "      <td>Koleos 2.0 dCi 175</td>\n",
       "      <td>2015</td>\n",
       "      <td>67263</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>15990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NISSAN</th>\n",
       "      <td>QASHQAI</td>\n",
       "      <td>Qashqai 1.2 DIG-T 115</td>\n",
       "      <td>2015</td>\n",
       "      <td>58998</td>\n",
       "      <td>Essence Sans Plomb</td>\n",
       "      <td>15989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RENAULT</th>\n",
       "      <td>KADJAR</td>\n",
       "      <td>Kadjar dCi 110 Energy eco²</td>\n",
       "      <td>2015</td>\n",
       "      <td>54525</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>15979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NISSAN</th>\n",
       "      <td>QASHQAI</td>\n",
       "      <td>Qashqai 1.6 dCi 130 Stop/Start</td>\n",
       "      <td>2015</td>\n",
       "      <td>75120</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>15760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RENAULT</th>\n",
       "      <td>TALISMAN</td>\n",
       "      <td>Talisman dCi 130 Energy</td>\n",
       "      <td>2015</td>\n",
       "      <td>65724</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>14990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            brand                             model  year      km  \\\n",
       "LEXUS          NX                       NX 300h 4WD  2015  39 816   \n",
       "RENAULT  TALISMAN           Talisman dCi 130 Energy  2015   24416   \n",
       "RENAULT    ESPACE  Espace dCi 160 Energy Twin Turbo  2015   51800   \n",
       "BMW       SERIE 2         Active Tourer 218d 150 ch  2015   49819   \n",
       "RENAULT    KOLEOS                Koleos 2.0 dCi 150  2015   62731   \n",
       "RENAULT    KOLEOS                Koleos 2.0 dCi 175  2015   67263   \n",
       "NISSAN    QASHQAI             Qashqai 1.2 DIG-T 115  2015   58998   \n",
       "RENAULT    KADJAR        Kadjar dCi 110 Energy eco²  2015   54525   \n",
       "NISSAN    QASHQAI    Qashqai 1.6 dCi 130 Stop/Start  2015   75120   \n",
       "RENAULT  TALISMAN           Talisman dCi 130 Energy  2015   65724   \n",
       "\n",
       "                                power  price  \n",
       "LEXUS    Essence / Courant Électrique  31980  \n",
       "RENAULT                        Diesel  19490  \n",
       "RENAULT                        Diesel  18990  \n",
       "BMW                            Diesel  18900  \n",
       "RENAULT                        Diesel  15990  \n",
       "RENAULT                        Diesel  15990  \n",
       "NISSAN             Essence Sans Plomb  15989  \n",
       "RENAULT                        Diesel  15979  \n",
       "NISSAN                         Diesel  15760  \n",
       "RENAULT                        Diesel  14990  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df.price <= 40000]\n",
    "df = df.nlargest(10, 'price')\n",
    "df.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask.futures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask.delayed\n",
    "The lazy computation is possible thanks to the computation graph, it is a DAG ( a Directed Acyclic Graph) which allows dask to know the different dependencies of the step computing, and, hence the parallelization. Every lazy dask function add one or more steps to this graph automaticaly. However, it is possible to build this graph by hand with the dask.delayed() function. This one is very usefull to parallelize a loop in the code. Just bellow we have two examples with a 'for' loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first one is a loop in which each iteration is independent of the previous one, this 'for' loop acts like a map. Into this last loop, we are multiplying each element by 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 10, 20, 30, 40, 50, 60, 70, 80, 90]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection = [0,1,2,3,4,5,6,7,8,9]\n",
    "result = []\n",
    "for e in collection:\n",
    "    r = delayed(lambda e:e*10)(e)\n",
    "    result.append(r)\n",
    "result = delayed(lambda x:x)(result)\n",
    "result.visualize('graph1.png')\n",
    "result.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to the '.visualize()' method wich allows us to display the graph built behind. We easily see that each iteration can be computed separately from each other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Graph](graph1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second example, bellow, also shows a 'for' loop but with a strong dependancy between iterations. Most of the calculations need the result of the previous operation. Let's see the graph below and the code that shows the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "a = 1\n",
    "b = 1\n",
    "add = lambda a,b:a+b\n",
    "for _ in range(2):\n",
    "    a = delayed(add)(1,a)\n",
    "    b = delayed(add)(1,b)\n",
    "    a = delayed(add)(a,b)\n",
    "\n",
    "result = a\n",
    "result.visualize('graph2.png')\n",
    "result.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Graph2](graph2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another advantage of dask.delayed is  the use of the decorator '@delayed'. Put that decorator over a function is a equivalent to the '.delayed(function)(args)'. It's a easy way to parallelize a group of function and it's possible to use it over a recursive function. Dask provides the example below wich computes the Fibonacci number. This function call itself twice, first for 'a = fib(n - 1)' and the second for 'b = fib(n - 2)', those last two calls are computed in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask import delayed, compute\n",
    "# https://distributed.dask.org/en/latest/task-launch.html\n",
    "\n",
    "@delayed\n",
    "def fib(n):\n",
    "    if n < 2:\n",
    "        return n\n",
    "    # We can use dask.delayed and dask.compute to launch\n",
    "    # computation from within tasks\n",
    "    a = fib(n - 1)  # these calls are delayed\n",
    "    b = fib(n - 2)\n",
    "    a, b = compute(a, b)  # execute both in parallel\n",
    "    return a + b\n",
    "\n",
    "f = fib(8)\n",
    "f.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also possible to generate the graph from a Python dictionary, where the key is the variable and the value is the computation to carry out. The method '.get()' triggers the computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.threaded import get\n",
    "from operator import add\n",
    "\n",
    "graph = {'x': 1,\n",
    " 'y': 2,\n",
    " 'z': (add, 'x', 'y'),\n",
    " 'w': (sum, ['x', 'y', 'z']),\n",
    " 'v': [(sum, ['w', 'z']), 2]}\n",
    "\n",
    "get(graph,'z')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask.futures\n",
    "Dask.future is used to compute in real-time, there is no more lazy computation in this part. dask.future extends the  native Python’s concurrent.futures. Let's see an example of how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from dask.distributed import wait, as_completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we are using the map operation where the function executed in argument is defined just below. We are simulating a complex time-undefined function with the primitive 'time.sleep()' which waits for the process for a while (it waits for the time specified in parameter). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complex_algorithm(e):\n",
    "    import time\n",
    "    time.sleep(e)\n",
    "    return e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next piece of code shows how to call the function complex_algorithm(5). The method '.submit()' returns a future object that follows the status of the function complex_algorithm(5) (either 'pending' or 'finish' when the algorithm has returned. The 'wait' is a blocking function that waits for the complex_algorithm to finish. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Future: pending, key: complex_algorithm-bdb7c61f884b46bb3acb38dfda348502>\n",
      "<Future: finished, type: builtins.int, key: complex_algorithm-bdb7c61f884b46bb3acb38dfda348502>\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "future = client.submit(complex_algorithm,5)\n",
    "print(future) # <Future: pending, ... >\n",
    "wait(future, timeout=12)\n",
    "print(future) # <Future: finished, ... >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function as_completed(futures) provides a Python generator that allows to iterate over a collection of 'future'.  The as_completed(futures) is a blocking function that awaits a new element to return. We can watch this behavior with the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27, 27, 7, 11, 15, 20, 15, 14, 26, 14, 24, 30, 9, 28, 16, 6, 9, 10, 19, 11, 14, 22, 26, 8, 12, 16, 18, 15, 7, 9, 9, 8, 28, 8, 14, 17, 12, 25, 22, 13, 14, 21, 18, 15, 22, 19, 16, 28, 20, 23, 16, 27, 12, 18, 24, 17, 12, 26, 16, 24, 15, 11, 16, 28, 9, 9, 25, 13, 12, 8, 28, 20, 11, 18, 9, 10, 20, 5, 8, 30, 20, 5, 27, 13, 26, 15, 29, 15, 18, 10, 17, 27, 14, 13, 15, 28, 7, 18, 9, 9, 24, 29, 28, 5, 22, 30, 20, 7, 10, 14, 22, 5, 8, 20, 23, 11, 17, 11, 5, 8, 29, 5, 26, 8, 10, 7, 7, 13, 29, 6, 24, 17, 12, 19, 15, 18, 19, 20, 13, 15, 29, 22, 15, 10, 6, 25, 11, 23, 15, 21, 20, 5, 30, 18, 19, 13, 27, 10, 29, 18, 5, 11, 17, 22, 6, 12, 19, 15, 18, 28, 7, 16, 6, 18, 6, 10, 9, 18, 29, 24, 24, 29, 5, 7, 17, 7, 29, 8, 9, 8, 19, 19, 29, 22, 27, 15, 17, 21, 5, 27]"
     ]
    }
   ],
   "source": [
    "import random\n",
    "collection = [random.randint(5,30) for _ in range(0,200)]\n",
    "print(collection,end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each integer in the 'collection' the function 'complex_function()' will wait for the time specify by this integer. Then, we trigger all the instance of 'complex_function()' at the same time, so the shortest time it waits for, the fastest it returns (until there are enough partitions, workers and/or threads to observe that phenomenon). An example of output is : 5,5,5,5,5,5,5,5,7,7,7,7,7,7,8,8,8,8,8,8,8,9,9,9,9,9,10,10,10,10,10,10,10,10,10,10,10,10,10,10,12,12,12,12,12,12,12,12,13,13,13,13,13,13,13,13,13,13,15,15,15,15,15,15,15,15,15,15,15,6,6,6,6,6,6,6,18,18,18,18,18,18,11,11,11,11,11,11,20,21,21,21,21,21,21,21,21,21,22,22,22,22,22,23,23,23,23,23,23,23,23,23,23,23,23,23,23,24,24,24,24,24,24,24,29,29,29,29,29,29,29,19,19,19,19,19,19,19,19,14,14,14,14,14,14,14,14,14,27,27,27,27,27,27,17,17,17,17,17,17,17,17,17,25,25,25,25,25,16,16,16,16,16,16,16,16,26,26,26,26,26,28,28,28,28,28,28,28,28,28,28,28,28,30,30,30,30,30,30,30,\n",
    "\n",
    "This example was run with ( Client(n_workers=5,threads_per_worker=3)), and we can see the (pseudo)order of the result that shows that the fastest algorithms return first (the results at begining of the list)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5,5,5,5,5,5,5,5,5,5,14,14,14,14,14,14,14,20,20,20,20,20,20,20,20,20,23,23,23,25,25,25,26,26,26,26,26,12,12,12,12,12,12,12,11,11,11,11,11,11,11,11,13,13,13,13,13,13,13,30,30,30,30,6,6,6,6,6,6,10,10,10,10,10,10,10,10,28,28,28,28,28,28,28,28,18,18,18,18,18,18,18,18,18,18,18,18,9,9,9,9,9,9,9,9,9,9,9,8,8,8,8,8,8,8,8,8,8,16,16,16,16,16,16,16,15,15,15,15,15,15,15,15,15,15,15,15,15,15,17,17,17,17,17,17,17,17,24,24,24,24,24,24,24,19,19,19,19,19,19,19,19,7,7,7,7,7,7,7,7,7,22,22,22,22,22,22,22,22,21,21,21,27,27,27,27,27,27,27,27,"
     ]
    }
   ],
   "source": [
    "futures = client.map(complex_algorithm,collection)\n",
    "import sys\n",
    "\n",
    "for future in as_completed(futures):\n",
    "    r = future.result()\n",
    "    sys.stdout.write(str(r)+',')\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diagnostics (distributed mode)\n",
    "At the start, the scheduler provides a dashboard, it is a Gui web interface where all the metrics are displayed in real time.\n",
    "\n",
    "![Dash1](Presentation/Dash1.png)\n",
    "![Dash2](Presentation/Dash2.png)\n",
    "![Dash5](Presentation/Dash5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " It is also possible to record all that information by the function 'performance_report()' that collects statistical profiling information about work. This function produces a web html file in the current folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import performance_report\n",
    "\n",
    "a = da.random.normal(size=(1000, 1000), chunks=(100, 100))\n",
    "res = a.dot(a.T).mean(axis=0)\n",
    "\n",
    "with performance_report(filename=\"dask-report.html\") as pr:\n",
    "    res.compute()\n",
    "    \n",
    "print(pr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask provides a local mode (=without any 'Client()' called) with which it is possible profile the code in-depth with:\n",
    "* 'Profiler': A class used to profile Dask’s execution at the task level.\n",
    "* 'ResourceProfiler': A class used to profile Dask’s execution at the resource level.\n",
    "* 'CacheProfiler': A class used to profile Dask’s execution at the scheduler cache level.\n",
    "* For more information : [https://docs.dask.org/en/latest/diagnostics-local.html](https://docs.dask.org/en/latest/diagnostics-local.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make it clean, at the end, we just have to close the connection with the scheduler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
